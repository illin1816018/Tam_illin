{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"WIKbNCpDKj2B"},"outputs":[],"source":["\n","from tensorflow import keras\n","from keras.layers import Dense\n","from tensorflow.keras.layers import Activation\n","from keras.layers import BatchNormalization\n","from tensorflow.keras.layers import UpSampling2D\n","from tensorflow.keras.layers import Flatten\n","from keras.layers import Input\n","from tensorflow.keras.layers import Conv2D\n","from keras.models import Model\n","from tensorflow.keras.layers import LeakyReLU, PReLU\n","from keras.layers import add\n","from keras.initializers import RandomNormal\n","from tensorflow.keras.optimizers import Adam\n","from tensorflow.keras.layers import Softmax\n","#from tensorflow.keras.layers import AveragePooling2D\n","#import tensorflow_addons as tfa\n","\n","# Residual block\n","def res_block_gen(model, kernal_size, filters, strides, initializer):\n","\n","    gen = model\n","\n","    model = Conv2D(filters = filters, kernel_size = kernal_size, strides = strides, padding = \"same\", kernel_initializer=initializer)(model)\n","    model = BatchNormalization(momentum = 0.5)(model)\n","    # Using Parametric ReLU\n","    model = PReLU(alpha_initializer='zeros', alpha_regularizer=None, alpha_constraint=None, shared_axes=[1,2])(model)\n","    model = Conv2D(filters = filters, kernel_size = kernal_size, strides = strides, padding = \"same\", kernel_initializer=initializer)(model)\n","    model = BatchNormalization(momentum = 0.5)(model)\n","\n","    model = add([gen, model])\n","\n","    return model\n","\n","\n","# Network Architecture is same as given in Paper https://arxiv.org/pdf/1609.04802.pdf\n","class Generator(object):\n","\n","    def __init__(self, noise_shape):\n","\n","        self.noise_shape = noise_shape\n","\n","    def generator(self):\n","        init = RandomNormal(stddev=0.02)\n","\n","        gen_input = Input(shape = self.noise_shape)\n","        model = Conv2D(filters = 64, kernel_size = 3, strides = 1, padding = \"same\", kernel_initializer=init)(gen_input)\n","        model = PReLU(alpha_initializer='zeros', alpha_regularizer=None, alpha_constraint=None, shared_axes=[1,2])(model)\n","\n","        gen_model = model\n","\n","        # Using 16 Residual Blocks\n","        for index in range(1):\n","\t        model = res_block_gen(model, 3, 64, 1, init)\n","\n","\n","        model = Conv2D(filters = 64, kernel_size = 3, strides = 1, padding = \"same\", kernel_initializer=init)(model)\n","        model = BatchNormalization(momentum = 0.5)(model)\n","        model = add([gen_model, model])\n","\n","        model = Conv2D(filters = 256, kernel_size = 3, strides = 1, padding = \"same\", kernel_initializer=init)(model)\n","\n","        # Task1 for classification\n","        model1= Conv2D(filters = 64, kernel_size = 3, strides = 1, padding = \"same\", kernel_initializer=init)(model)\n","        model1= Conv2D(filters = 4, kernel_size = 3, strides = 1, padding = \"same\", kernel_initializer=init)(model1)\n","        output1=Softmax()(model1)\n","\n","        # Task2 for downscaling with 3 upsampling blocks\n","        model2 = Conv2D(filters = 128, kernel_size = 3, strides = 1, padding = \"same\", kernel_initializer=init)(model)\n","        model2 = UpSampling2D(size = 2)(model2)\n","        model2 = PReLU(alpha_initializer='zeros', alpha_regularizer=None, alpha_constraint=None, shared_axes=[1,2])(model2)\n","\n","        model2 = Conv2D(filters = 128, kernel_size = 3, strides = 1, padding = \"same\", kernel_initializer=init)(model2)\n","        model2 = UpSampling2D(size = 3)(model2)\n","        model2 = PReLU(alpha_initializer='zeros', alpha_regularizer=None, alpha_constraint=None, shared_axes=[1,2])(model2)\n","\n","        model2 = Conv2D(filters = 128, kernel_size = 3, strides = 1, padding = \"same\", kernel_initializer=init)(model2)\n","        model2 = UpSampling2D(size = 2)(model2)\n","        model2 = PReLU(alpha_initializer='zeros', alpha_regularizer=None, alpha_constraint=None, shared_axes=[1,2])(model2)\n","\n","        output2 = Conv2D(filters = 1, kernel_size = 9, strides = 1, padding = \"same\", kernel_initializer=init)(model2)\n","\t#    model = Activation('tanh')(model)\n","\n","        generator_model = Model(inputs = gen_input, outputs = [output1, output2])\n","\n","        return generator_model\n","\n","# model_gen=Generator((13, 16, 1)).generator()\n","# model_gen.summary()\n","# from tensorflow.keras.utils import plot_model\n","# plot_model(model_gen)"]},{"cell_type":"code","source":["! pip freeze numpy"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"LLoajWc7GuIf","executionInfo":{"status":"ok","timestamp":1701765158554,"user_tz":-360,"elapsed":1606,"user":{"displayName":"Tamjidul Islam Illin","userId":"09875857063504118268"}},"outputId":"595bdc1d-3c6e-482b-8d43-0d5c2cf9fe7f"},"execution_count":1,"outputs":[{"output_type":"stream","name":"stdout","text":["absl-py==1.4.0\n","aiohttp==3.9.1\n","aiosignal==1.3.1\n","alabaster==0.7.13\n","albumentations==1.3.1\n","altair==4.2.2\n","anyio==3.7.1\n","appdirs==1.4.4\n","argon2-cffi==23.1.0\n","argon2-cffi-bindings==21.2.0\n","array-record==0.5.0\n","arviz==0.15.1\n","astropy==5.3.4\n","astunparse==1.6.3\n","async-timeout==4.0.3\n","atpublic==4.0\n","attrs==23.1.0\n","audioread==3.0.1\n","autograd==1.6.2\n","Babel==2.13.1\n","backcall==0.2.0\n","beautifulsoup4==4.11.2\n","bidict==0.22.1\n","bigframes==0.15.0\n","bleach==6.1.0\n","blinker==1.4\n","blis==0.7.11\n","blosc2==2.0.0\n","bokeh==3.3.1\n","bqplot==0.12.42\n","branca==0.7.0\n","build==1.0.3\n","CacheControl==0.13.1\n","cachetools==5.3.2\n","catalogue==2.0.10\n","certifi==2023.11.17\n","cffi==1.16.0\n","chardet==5.2.0\n","charset-normalizer==3.3.2\n","chex==0.1.7\n","click==8.1.7\n","click-plugins==1.1.1\n","cligj==0.7.2\n","cloudpickle==2.2.1\n","cmake==3.27.7\n","cmdstanpy==1.2.0\n","colorcet==3.0.1\n","colorlover==0.3.0\n","colour==0.1.5\n","community==1.0.0b1\n","confection==0.1.4\n","cons==0.4.6\n","contextlib2==21.6.0\n","contourpy==1.2.0\n","cryptography==41.0.7\n","cufflinks==0.17.3\n","cupy-cuda11x==11.0.0\n","cvxopt==1.3.2\n","cvxpy==1.3.2\n","cycler==0.12.1\n","cymem==2.0.8\n","Cython==3.0.6\n","dask==2023.8.1\n","datascience==0.17.6\n","db-dtypes==1.1.1\n","dbus-python==1.2.18\n","debugpy==1.6.6\n","decorator==4.4.2\n","defusedxml==0.7.1\n","diskcache==5.6.3\n","distributed==2023.8.1\n","distro==1.7.0\n","dlib==19.24.2\n","dm-tree==0.1.8\n","docutils==0.18.1\n","dopamine-rl==4.0.6\n","duckdb==0.9.2\n","earthengine-api==0.1.381\n","easydict==1.11\n","ecos==2.0.12\n","editdistance==0.6.2\n","eerepr==0.0.4\n","en-core-web-sm @ https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-3.6.0/en_core_web_sm-3.6.0-py3-none-any.whl#sha256=83276fc78a70045627144786b52e1f2728ad5e29e5e43916ec37ea9c26a11212\n","entrypoints==0.4\n","et-xmlfile==1.1.0\n","etils==1.5.2\n","etuples==0.3.9\n","exceptiongroup==1.2.0\n","fastai==2.7.13\n","fastcore==1.5.29\n","fastdownload==0.0.7\n","fastjsonschema==2.19.0\n","fastprogress==1.0.3\n","fastrlock==0.8.2\n","filelock==3.13.1\n","fiona==1.9.5\n","firebase-admin==5.3.0\n","Flask==2.2.5\n","flatbuffers==23.5.26\n","flax==0.7.5\n","folium==0.14.0\n","fonttools==4.45.1\n","frozendict==2.3.10\n","frozenlist==1.4.0\n","fsspec==2023.6.0\n","future==0.18.3\n","gast==0.5.4\n","gcsfs==2023.6.0\n","GDAL==3.4.3\n","gdown==4.6.6\n","geemap==0.28.2\n","gensim==4.3.2\n","geocoder==1.38.1\n","geographiclib==2.0\n","geopandas==0.13.2\n","geopy==2.3.0\n","gin-config==0.5.0\n","glob2==0.7\n","google==2.0.3\n","google-ai-generativelanguage==0.3.3\n","google-api-core==2.11.1\n","google-api-python-client==2.84.0\n","google-auth==2.17.3\n","google-auth-httplib2==0.1.1\n","google-auth-oauthlib==1.0.0\n","google-cloud-aiplatform==1.36.4\n","google-cloud-bigquery==3.12.0\n","google-cloud-bigquery-connection==1.12.1\n","google-cloud-bigquery-storage==2.23.0\n","google-cloud-core==2.3.3\n","google-cloud-datastore==2.15.2\n","google-cloud-firestore==2.11.1\n","google-cloud-functions==1.13.3\n","google-cloud-iam==2.12.2\n","google-cloud-language==2.9.1\n","google-cloud-resource-manager==1.10.4\n","google-cloud-storage==2.8.0\n","google-cloud-translate==3.11.3\n","google-colab @ file:///colabtools/dist/google-colab-1.0.0.tar.gz#sha256=96e8c242fb55a2c189a2cf1f0c80424a8ee10e7e331ce75172c3806ac57ba026\n","google-crc32c==1.5.0\n","google-generativeai==0.2.2\n","google-pasta==0.2.0\n","google-resumable-media==2.6.0\n","googleapis-common-protos==1.61.0\n","googledrivedownloader==0.4\n","graphviz==0.20.1\n","greenlet==3.0.1\n","grpc-google-iam-v1==0.12.7\n","grpcio==1.59.3\n","grpcio-status==1.48.2\n","gspread==3.4.2\n","gspread-dataframe==3.3.1\n","gym==0.25.2\n","gym-notices==0.0.8\n","h5netcdf==1.3.0\n","h5py==3.9.0\n","holidays==0.37\n","holoviews==1.17.1\n","html5lib==1.1\n","httpimport==1.3.1\n","httplib2==0.22.0\n","huggingface-hub==0.19.4\n","humanize==4.7.0\n","hyperopt==0.2.7\n","ibis-framework==6.2.0\n","idna==3.6\n","imageio==2.31.6\n","imageio-ffmpeg==0.4.9\n","imagesize==1.4.1\n","imbalanced-learn==0.10.1\n","imgaug==0.4.0\n","importlib-metadata==6.8.0\n","importlib-resources==6.1.1\n","imutils==0.5.4\n","inflect==7.0.0\n","iniconfig==2.0.0\n","install==1.3.5\n","intel-openmp==2023.2.0\n","ipyevents==2.0.2\n","ipyfilechooser==0.6.0\n","ipykernel==5.5.6\n","ipyleaflet==0.18.0\n","ipython==7.34.0\n","ipython-genutils==0.2.0\n","ipython-sql==0.5.0\n","ipytree==0.2.2\n","ipywidgets==7.7.1\n","itsdangerous==2.1.2\n","jax==0.4.20\n","jaxlib @ https://storage.googleapis.com/jax-releases/cuda11/jaxlib-0.4.20+cuda11.cudnn86-cp310-cp310-manylinux2014_x86_64.whl#sha256=01be66238133f884bf5adf15cd7eaaf8445f9d4b056c5c64df28a997a6aff2fe\n","jeepney==0.7.1\n","jieba==0.42.1\n","Jinja2==3.1.2\n","joblib==1.3.2\n","jsonpickle==3.0.2\n","jsonschema==4.19.2\n","jsonschema-specifications==2023.11.2\n","jupyter-client==6.1.12\n","jupyter-console==6.1.0\n","jupyter-server==1.24.0\n","jupyter_core==5.5.0\n","jupyterlab-widgets==3.0.9\n","jupyterlab_pygments==0.3.0\n","kaggle==1.5.16\n","keras==2.14.0\n","keyring==23.5.0\n","kiwisolver==1.4.5\n","langcodes==3.3.0\n","launchpadlib==1.10.16\n","lazr.restfulclient==0.14.4\n","lazr.uri==1.0.6\n","lazy_loader==0.3\n","libclang==16.0.6\n","librosa==0.10.1\n","lida==0.0.10\n","lightgbm==4.1.0\n","linkify-it-py==2.0.2\n","llmx==0.0.15a0\n","llvmlite==0.41.1\n","locket==1.0.0\n","logical-unification==0.4.6\n","lxml==4.9.3\n","malloy==2023.1064\n","Markdown==3.5.1\n","markdown-it-py==3.0.0\n","MarkupSafe==2.1.3\n","matplotlib==3.7.1\n","matplotlib-inline==0.1.6\n","matplotlib-venn==0.11.9\n","mdit-py-plugins==0.4.0\n","mdurl==0.1.2\n","miniKanren==1.0.3\n","missingno==0.5.2\n","mistune==0.8.4\n","mizani==0.9.3\n","mkl==2023.2.0\n","ml-dtypes==0.2.0\n","mlxtend==0.22.0\n","more-itertools==10.1.0\n","moviepy==1.0.3\n","mpmath==1.3.0\n","msgpack==1.0.7\n","multidict==6.0.4\n","multipledispatch==1.0.0\n","multitasking==0.0.11\n","murmurhash==1.0.10\n","music21==9.1.0\n","natsort==8.4.0\n","nbclassic==1.0.0\n","nbclient==0.9.0\n","nbconvert==6.5.4\n","nbformat==5.9.2\n","nest-asyncio==1.5.8\n","networkx==3.2.1\n","nibabel==4.0.2\n","nltk==3.8.1\n","notebook==6.5.5\n","notebook_shim==0.2.3\n","numba==0.58.1\n","numexpr==2.8.7\n","numpy==1.23.5\n","oauth2client==4.1.3\n","oauthlib==3.2.2\n","opencv-contrib-python==4.8.0.76\n","opencv-python==4.8.0.76\n","opencv-python-headless==4.8.1.78\n","openpyxl==3.1.2\n","opt-einsum==3.3.0\n","optax==0.1.7\n","orbax-checkpoint==0.4.3\n","osqp==0.6.2.post8\n","packaging==23.2\n","pandas==1.5.3\n","pandas-datareader==0.10.0\n","pandas-gbq==0.17.9\n","pandas-stubs==1.5.3.230304\n","pandocfilters==1.5.0\n","panel==1.3.4\n","param==2.0.1\n","parso==0.8.3\n","parsy==2.1\n","partd==1.4.1\n","pathlib==1.0.1\n","pathy==0.10.3\n","patsy==0.5.3\n","peewee==3.17.0\n","pexpect==4.9.0\n","pickleshare==0.7.5\n","Pillow==9.4.0\n","pip-tools==6.13.0\n","platformdirs==4.0.0\n","plotly==5.15.0\n","plotnine==0.12.4\n","pluggy==1.3.0\n","polars==0.17.3\n","pooch==1.8.0\n","portpicker==1.5.2\n","prefetch-generator==1.0.3\n","preshed==3.0.9\n","prettytable==3.9.0\n","proglog==0.1.10\n","progressbar2==4.2.0\n","prometheus-client==0.19.0\n","promise==2.3\n","prompt-toolkit==3.0.41\n","prophet==1.1.5\n","proto-plus==1.22.3\n","protobuf==3.20.3\n","psutil==5.9.5\n","psycopg2==2.9.9\n","ptyprocess==0.7.0\n","py-cpuinfo==9.0.0\n","py4j==0.10.9.7\n","pyarrow==9.0.0\n","pyasn1==0.5.1\n","pyasn1-modules==0.3.0\n","pycocotools==2.0.7\n","pycparser==2.21\n","pyct==0.5.0\n","pydantic==1.10.13\n","pydata-google-auth==1.8.2\n","pydot==1.4.2\n","pydot-ng==2.0.0\n","pydotplus==2.0.2\n","PyDrive==1.3.1\n","PyDrive2==1.6.3\n","pyerfa==2.0.1.1\n","pygame==2.5.2\n","Pygments==2.16.1\n","PyGObject==3.42.1\n","PyJWT==2.3.0\n","pymc==5.7.2\n","pymystem3==0.2.0\n","PyOpenGL==3.1.7\n","pyOpenSSL==23.3.0\n","pyparsing==3.1.1\n","pyperclip==1.8.2\n","pyproj==3.6.1\n","pyproject_hooks==1.0.0\n","pyshp==2.3.1\n","PySocks==1.7.1\n","pytensor==2.14.2\n","pytest==7.4.3\n","python-apt==0.0.0\n","python-box==7.1.1\n","python-dateutil==2.8.2\n","python-louvain==0.16\n","python-slugify==8.0.1\n","python-utils==3.8.1\n","pytz==2023.3.post1\n","pyviz_comms==3.0.0\n","PyWavelets==1.5.0\n","PyYAML==6.0.1\n","pyzmq==23.2.1\n","qdldl==0.1.7.post0\n","qudida==0.0.4\n","ratelim==0.1.6\n","referencing==0.31.1\n","regex==2023.6.3\n","requests==2.31.0\n","requests-oauthlib==1.3.1\n","requirements-parser==0.5.0\n","rich==13.7.0\n","rpds-py==0.13.2\n","rpy2==3.4.2\n","rsa==4.9\n","safetensors==0.4.1\n","scikit-image==0.19.3\n","scikit-learn==1.2.2\n","scipy==1.11.4\n","scooby==0.9.2\n","scs==3.2.4.post1\n","seaborn==0.12.2\n","SecretStorage==3.3.1\n","Send2Trash==1.8.2\n","shapely==2.0.2\n","six==1.16.0\n","sklearn-pandas==2.2.0\n","smart-open==6.4.0\n","sniffio==1.3.0\n","snowballstemmer==2.2.0\n","sortedcontainers==2.4.0\n","soundfile==0.12.1\n","soupsieve==2.5\n","soxr==0.3.7\n","spacy==3.6.1\n","spacy-legacy==3.0.12\n","spacy-loggers==1.0.5\n","Sphinx==5.0.2\n","sphinxcontrib-applehelp==1.0.7\n","sphinxcontrib-devhelp==1.0.5\n","sphinxcontrib-htmlhelp==2.0.4\n","sphinxcontrib-jsmath==1.0.1\n","sphinxcontrib-qthelp==1.0.6\n","sphinxcontrib-serializinghtml==1.1.9\n","SQLAlchemy==2.0.23\n","sqlglot==17.16.2\n","sqlparse==0.4.4\n","srsly==2.4.8\n","stanio==0.3.0\n","statsmodels==0.14.0\n","sympy==1.12\n","tables==3.8.0\n","tabulate==0.9.0\n","tbb==2021.11.0\n","tblib==3.0.0\n","tenacity==8.2.3\n","tensorboard==2.14.1\n","tensorboard-data-server==0.7.2\n","tensorflow==2.14.0\n","tensorflow-datasets==4.9.3\n","tensorflow-estimator==2.14.0\n","tensorflow-gcs-config==2.14.0\n","tensorflow-hub==0.15.0\n","tensorflow-io-gcs-filesystem==0.34.0\n","tensorflow-metadata==1.14.0\n","tensorflow-probability==0.22.0\n","tensorstore==0.1.45\n","termcolor==2.3.0\n","terminado==0.18.0\n","text-unidecode==1.3\n","textblob==0.17.1\n","tf-slim==1.1.0\n","thinc==8.1.12\n","threadpoolctl==3.2.0\n","tifffile==2023.9.26\n","tinycss2==1.2.1\n","tokenizers==0.15.0\n","toml==0.10.2\n","tomli==2.0.1\n","toolz==0.12.0\n","torch @ https://download.pytorch.org/whl/cu118/torch-2.1.0%2Bcu118-cp310-cp310-linux_x86_64.whl#sha256=a81b554184492005543ddc32e96469f9369d778dedd195d73bda9bed407d6589\n","torchaudio @ https://download.pytorch.org/whl/cu118/torchaudio-2.1.0%2Bcu118-cp310-cp310-linux_x86_64.whl#sha256=cdfd0a129406155eee595f408cafbb92589652da4090d1d2040f5453d4cae71f\n","torchdata==0.7.0\n","torchsummary==1.5.1\n","torchtext==0.16.0\n","torchvision @ https://download.pytorch.org/whl/cu118/torchvision-0.16.0%2Bcu118-cp310-cp310-linux_x86_64.whl#sha256=033712f65d45afe806676c4129dfe601ad1321d9e092df62b15847c02d4061dc\n","tornado==6.3.2\n","tqdm==4.66.1\n","traitlets==5.7.1\n","traittypes==0.2.1\n","transformers==4.35.2\n","triton==2.1.0\n","tweepy==4.14.0\n","typer==0.9.0\n","types-pytz==2023.3.1.1\n","types-setuptools==69.0.0.0\n","typing_extensions==4.5.0\n","tzlocal==5.2\n","uc-micro-py==1.0.2\n","uritemplate==4.1.1\n","urllib3==2.0.7\n","vega-datasets==0.9.0\n","wadllib==1.3.6\n","wasabi==1.1.2\n","wcwidth==0.2.12\n","webcolors==1.13\n","webencodings==0.5.1\n","websocket-client==1.6.4\n","Werkzeug==3.0.1\n","widgetsnbextension==3.6.6\n","wordcloud==1.9.2\n","wrapt==1.14.1\n","xarray==2023.7.0\n","xarray-einstats==0.6.0\n","xgboost==2.0.2\n","xlrd==2.0.1\n","xxhash==3.4.1\n","xyzservices==2023.10.1\n","yarl==1.9.3\n","yellowbrick==1.5\n","yfinance==0.2.32\n","zict==3.0.0\n","zipp==3.17.0\n"]}]},{"cell_type":"code","source":["from Network import Generator\n","from keras.models import Model\n","import numpy as np\n","from keras.layers import Input\n","from tensorflow.keras.optimizers import Adam\n","import numpy as np\n","from tqdm import tqdm\n","from numpy import save\n","from numpy import load\n","import tensorflow.keras.backend as K\n","import tensorflow as tf\n","#from keras.preprocessing.image import ImageDataGenerator\n","from keras.callbacks import Callback, ReduceLROnPlateau, EarlyStopping, ModelCheckpoint\n","from sklearn.preprocessing import StandardScaler\n","from sklearn.preprocessing import MinMaxScaler\n","import xarray as xr\n","from tensorflow.keras.utils import to_categorical\n","a = 1\n","# def my_MSE_weighted(y_true, y_pred):\n","#   weights= tf.clip_by_value(y_true, K.log(0.1+1), K.log(100.0+1))\n","#   return K.mean(tf.multiply(weights, tf.abs(tf.subtract(y_pred, y_true))))\n","\n","n_classes=4\n","def weighted_categorical_crossentropy(weights):\n","    weights=weights.reshape((1,1,1,n_classes))\n","    def wcce(y_true, y_pred):\n","        Kweights=K.constant(weights)\n","        y_true=K.cast(y_true,y_pred.dtype)\n","\n","\n","        return K.categorical_crossentropy(y_true, y_pred) * K.sum(y_true * Kweights, axis=-1)\n","\n","\n","    return wcce\n","\n","class_weights=np.array([4, 19, 23, 56]) # inverse percentage of classes\n","class_loss = weighted_categorical_crossentropy(weights=class_weights)\n","\n","def make_FSS_loss(mask_size):  # choose any mask size for calculating densities\n","\n","    def my_FSS_loss(y_true, y_pred):\n","\n","        # First: DISCRETIZE y_true and y_pred to have only binary values 0/1\n","        # (or close to those for soft discretization)\n","        want_hard_discretization = False\n","\n","        # This example assumes that y_true, y_pred have the shape (None, N, N, 1).\n","        a = y_true.simpy()\n","        cutoff = 0.5  # choose the cut off value for discretization\n","\n","        if (want_hard_discretization):\n","           # Hard discretization:\n","           # can use that in metric, but not in loss\n","           y_true_binary = tf.where(y_true>cutoff, 1.0, 0.0)\n","           y_pred_binary = tf.where(y_pred>cutoff, 1.0, 0.0)\n","\n","        else:\n","           # Soft discretization\n","           c = 10 # make sigmoid function steep\n","           y_true_binary = tf.math.sigmoid( c * ( y_true - cutoff ))\n","           y_pred_binary = tf.math.sigmoid( c * ( y_pred - cutoff ))\n","\n","        # Done with discretization.\n","\n","        # To calculate densities: apply average pooling to y_true.\n","        # Result is O(mask_size)(i,j) in Eq. (2) of [RL08].\n","        # Since we use AveragePooling, this automatically includes the factor 1/n^2 in Eq. (2).\n","        pool1 = tf.keras.layers.AveragePooling2D(pool_size=(mask_size, mask_size), strides=(1, 1),\n","           padding='same')\n","        y_true_density = pool1(y_true_binary);\n","        # Need to know for normalization later how many pixels there are after pooling\n","        n_density_pixels = tf.cast( (tf.shape(y_true_density)[1] * tf.shape(y_true_density)[2]) ,\n","           tf.float32 )\n","\n","        # To calculate densities: apply average pooling to y_pred.\n","        # Result is M(mask_size)(i,j) in Eq. (3) of [RL08].\n","        # Since we use AveragePooling, this automatically includes the factor 1/n^2 in Eq. (3).\n","        pool2 = tf.keras.layers.AveragePooling2D(pool_size=(mask_size, mask_size),\n","                                                 strides=(1, 1), padding='same')\n","        y_pred_density = pool2(y_pred_binary);\n","\n","        # This calculates MSE(n) in Eq. (5) of [RL08].\n","        # Since we use MSE function, this automatically includes the factor 1/(Nx*Ny) in Eq. (5).\n","        MSE_n = tf.keras.losses.MeanSquaredError()(y_true_density, y_pred_density)\n","\n","        # To calculate MSE_n_ref in Eq. (7) of [RL08] efficiently:\n","        # multiply each image with itself to get square terms, then sum up those terms.\n","\n","        # Part 1 - calculate sum( O(n)i,j^2\n","        # Take y_true_densities as image and multiply image by itself.\n","        O_n_squared_image = tf.keras.layers.Multiply()([y_true_density, y_true_density])\n","        # Flatten result, to make it easier to sum over it.\n","        O_n_squared_vector = tf.keras.layers.Flatten()(O_n_squared_image)\n","        # Calculate sum over all terms.\n","        O_n_squared_sum = tf.reduce_sum(O_n_squared_vector)\n","\n","        # Same for y_pred densitites:\n","        # Multiply image by itself\n","        M_n_squared_image = tf.keras.layers.Multiply()([y_pred_density, y_pred_density])\n","        # Flatten result, to make it easier to sum over it.\n","        M_n_squared_vector = tf.keras.layers.Flatten()(M_n_squared_image)\n","        # Calculate sum over all terms.\n","        M_n_squared_sum = tf.reduce_sum(M_n_squared_vector)\n","\n","        MSE_n_ref = (O_n_squared_sum + M_n_squared_sum) / n_density_pixels\n","\n","        # FSS score according to Eq. (6) of [RL08].\n","        # FSS = 1 - (MSE_n / MSE_n_ref)\n","\n","        # FSS is a number between 0 and 1, with maximum of 1 (optimal value).\n","        # In loss functions: We want to MAXIMIZE FSS (best value is 1),\n","        # so return only the last term to minimize.\n","\n","        # Avoid division by zero if MSE_n_ref == 0\n","        # MSE_n_ref = 0 only if both input images contain only zeros.\n","        # In that case both images match exactly, i.e. we should return 0.\n","        my_epsilon = tf.keras.backend.epsilon()  # this is 10^(-7)\n","\n","        if (want_hard_discretization):\n","           if MSE_n_ref == 0:\n","              return( MSE_n )\n","           else:\n","              return( MSE_n / MSE_n_ref )\n","        else:\n","           return (MSE_n / (MSE_n_ref + my_epsilon) )\n","\n","    return my_FSS_loss\n","\n","mask_size = 3\n","\n","\n","image_shape_hr = (24,36,1)\n","image_shape_lr = (2,3,5) # coarse input\n","downscale_factor = 12\n","# load low resolution other variables data for training\n","# load low resolution data for training reforecast\n","PATH = '/scratch/users/nus/e0560091/data/' # CHANGE TO YOUR OWN PATH\n","reforecast_train=load('X_train_ensemble.npy')\n","\n","# load high resolution data for training WRF\n","yhr_train=load('S:\\Climate SRGAN\\srganMedium-main\\Model3\\y_hr_train (6).npy')\n","\n","#load low resolution data for validation\n","reforecast_val=load('X_val_ensemble.npy')\n","\n","#load high resolution data for validation\n","yhr_val=load('S:\\Climate SRGAN\\srganMedium-main\\Model3\\y_hr_val (6).npy')\n","\n","# load stage4 classified image for training\n","\n","reanalysis_class_train=load('S:\\Climate SRGAN\\srganMedium-main\\Model3\\y_class_train (6).npy')\n","reanalysis_class_train = np.clip(np.round(reanalysis_class_train).astype(int), 0, 4 - 1)\n","reanalysis_class_train_vector=reanalysis_class_train.reshape(-1,)\n","reanalysis_class_val=load('S:\\Climate SRGAN\\srganMedium-main\\Model3\\y_class_val (6).npy')\n","# convert stage4_class to categorical variable\n","unique_values = np.unique(reanalysis_class_train)\n","print(unique_values)\n","reanalysis_class_train=to_categorical(reanalysis_class_train, num_classes=n_classes)\n","reanalysis_class_val=to_categorical(reanalysis_class_val, num_classes=n_classes)\n","\n","#****************************************************************************************\n","\n","def train(epochs, batch_size):\n","\n","    x_train_lr=reforecast_train\n","    y_train_hr=yhr_train\n","\n","    x_val_lr=reforecast_val\n","    y_val_hr=yhr_val\n","\n","    x_train_lr=reforecast_train\n","    y_train_class=reanalysis_class_train\n","    y_train_hr=yhr_train\n","\n","    x_val_lr=reforecast_val\n","    y_val_class=reanalysis_class_val\n","    y_val_hr=yhr_val\n","\n","    batch_count = int(x_train_lr.shape[0] / batch_size)\n","\n","    generator = Generator(image_shape_lr).generator()\n","    generator.compile(loss=[class_loss, make_FSS_loss(mask_size)], optimizer = Adam(learning_rate=0.0001, beta_1=0.9), loss_weights=[0.01, 1.0],metrics=['mae', 'mse'])\n","    loss_file = open('losses.txt' , 'w+')\n","    loss_file.close()\n","\n","    for e in range(1, epochs+1):\n","\n","        print ('-'*15, 'Epoch %d' % e, '-'*15)\n","\n","        for _ in tqdm(range(batch_count)):\n","\n","            rand_nums = np.random.randint(0, x_train_lr.shape[0], size=batch_size)\n","\n","            x_lr = x_train_lr[rand_nums]\n","            y_hr = y_train_hr[rand_nums]\n","            y_class=y_train_class[rand_nums]\n","\n","            gen_loss=generator.train_on_batch(x_lr, [y_class,y_hr])\n","        gen_loss = str(gen_loss)\n","        #from here\n","        gen_loss, y_pred = generator.train_on_batch(x_lr, [y_class, y_hr])\n","\n","        # Save the values of y_pred to a file\n","        with open('y_pred_values.txt', 'a') as file:\n","            file.write('epoch%d : y_pred values = %s\\n' % (e, str(y_pred))) #here\n","        val_loss = generator.evaluate(x_val_lr, [y_val_class, y_val_hr], verbose=0)\n","        val_loss = str(val_loss)\n","        loss_file = open('losses.txt' , 'a')\n","        loss_file.write('epoch%d : generator_loss = %s; validation_loss = %s\\n'\n","                        %(e, gen_loss, val_loss))\n","\n","        loss_file.close()\n","        if e <=10:\n","            if e  % 5== 0:\n","                generator.save('gen_model%d.h5' % e)\n","        else:\n","             if e  % 10 == 0:\n","                generator.save('gen_model%d.h5' % e)\n","\n","\n","\n","train(5 , 64)\n","\n","\n","\n"],"metadata":{"id":"7JWGxDIEK-W2","colab":{"base_uri":"https://localhost:8080/","height":383},"executionInfo":{"status":"error","timestamp":1701699565799,"user_tz":-360,"elapsed":648,"user":{"displayName":"Tamjidul Islam Illin","userId":"09875857063504118268"}},"outputId":"a3ea55e7-b578-44ce-eb8e-dc969c03899c"},"execution_count":null,"outputs":[{"output_type":"error","ename":"ModuleNotFoundError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)","\u001b[0;32m<ipython-input-4-d2507ea39533>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mNetwork\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mGenerator\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodels\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mModel\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mInput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimizers\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mAdam\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'Network'","","\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"],"errorDetails":{"actions":[{"action":"open_url","actionText":"Open Examples","url":"/notebooks/snippets/importing_libraries.ipynb"}]}}]}]}